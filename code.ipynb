{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBCSTDyXQ6HJ",
        "outputId": "39fb5299-5e47-4f45-88f1-f088096e6b22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n",
            "3.7.13 (default, Apr 24 2022, 01:04:09) \n",
            "[GCC 7.5.0]\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "print(tf.__version__)\n",
        "import sys\n",
        "print(sys.version)\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RzyxC2xhSZRl"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/in_domain_train.csv\")\n",
        "data_dev = pd.read_csv(\"/content/in_domain_dev.csv\")\n",
        "data = data.values\n",
        "data_dev = data_dev.values\n",
        "x_train = data[:,1]\n",
        "y_train = data[:,2]\n",
        "\n",
        "x_dev = data_dev[:,1]\n",
        "y_dev = data_dev[:,2]\n",
        "\n",
        "y = np.concatenate((y_dev,y_train))\n",
        "x = np.concatenate((x_dev,x_train))\n",
        "import random\n",
        "random.shuffle(y)\n",
        "random.shuffle(x)  \n",
        "y_t_0 = y[1500:]\n",
        "y_d_0 = y[:1500]\n",
        "x_t_0 = x[1500:]\n",
        "x_d_0 = x[:1500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfro3TVLSlgj",
        "outputId": "32b1c599-03f2-4353-d613-04ed24ad99a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\t307365\thttp://lang-8.com/18840/journals/84655\t21\tThey asked me to explain `` Ionic Bond `` in English .\n",
            " 65781\n"
          ]
        }
      ],
      "source": [
        "f = open('entries.txt')\n",
        "lines=f.readlines()\n",
        "sentences = []\n",
        "y = []\n",
        "line = 0\n",
        "cur = 0\n",
        "for x in lines:\n",
        "    cur = cur +1\n",
        "    if x=='\\n' : continue\n",
        "    else: line=line+1\n",
        "    if line>=60000: \n",
        "        print(x,cur)\n",
        "        break\n",
        "    sentences.append(x.split('\\t')[4])\n",
        "    if x.split('\\t')[0] == '0':\n",
        "        y.append(1)\n",
        "    else:\n",
        "        y.append(0)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D50Fr0_SoXu",
        "outputId": "644054c0-176e-4da5-c875-ea5c70bc914b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59999 59999\n"
          ]
        }
      ],
      "source": [
        "print(len(y),len(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfjX81wPSxa4",
        "outputId": "6ad50dec-2f5c-4bc2-ff66-46118cceb819"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29389 30610\n"
          ]
        }
      ],
      "source": [
        "zeros = 0\n",
        "ones = 0\n",
        "for l in y:\n",
        "    if l==0:\n",
        "        zeros = zeros+1\n",
        "    else:\n",
        "        ones = ones+1\n",
        "print(zeros,ones)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XX7AWNeTpJ6",
        "outputId": "8df09bb6-50c7-4b89-d29a-e349696b6d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62351 6500 ['I really miss them .\\n' \"I 'm not sure how I spend more 3 weeks here .\"\n",
            " 'Oh my god !\\n'] ['Good luck on your new start !\\n'\n",
            " 'My teacher is going to move to change his job .\\n'\n",
            " 'He is a so nice guy and taught me English very kindly and was willing to accept my getting off the track .\\n']\n"
          ]
        }
      ],
      "source": [
        "y_t_1 = y[5000:]\n",
        "y_d_1 = y[:5000]\n",
        "x_t_1 = sentences[5000:]\n",
        "x_d_1 = sentences[:5000]\n",
        "\n",
        "y_t = np.concatenate((y_t_1,y_t_0.tolist()))\n",
        "y_d = np.concatenate((y_d_1,y_d_0.tolist()))\n",
        "sentences_t = np.concatenate((x_t_1,x_t_0))\n",
        "sentences_d = np.concatenate((x_d_1,x_d_0))\n",
        "\n",
        "print(len(y_t),len(y_d),sentences_t[:3],sentences_d[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GGXAxB5ZTvj4"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "max_length = 120\n",
        "trunc_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(sentences_t)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index)+1\n",
        "sequences = tokenizer.texts_to_sequences(sentences_t)\n",
        "padded = pad_sequences(sequences,maxlen=max_length)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(sentences_d)\n",
        "testing_padded = pad_sequences(testing_sequences,maxlen=max_length)\n",
        "\n",
        "y_train_np = np.array(y_t,np.float32)\n",
        "y_dev_np = np.array(y_d,np.float32)\n",
        "testing_padded_np = np.array(testing_padded,np.float32)\n",
        "padded_np = np.array(padded,np.float32)\n",
        "\n",
        "y_train_tf = tf.convert_to_tensor(y_train_np, np.float32)\n",
        "y_dev_tf = tf.convert_to_tensor(y_dev_np, np.float32)\n",
        "testing_padded_tf = tf.convert_to_tensor(testing_padded_np, np.float32)\n",
        "padded_tf = tf.convert_to_tensor(padded_np, np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EMs1tOVERWo",
        "outputId": "1337708b-5f78-45ff-bd50-eabf3a35760b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0000e+00 0.0000e+00 0.0000e+00 ... 9.1000e+01 6.9100e+02 7.0000e+01]\n",
            " [0.0000e+00 0.0000e+00 0.0000e+00 ... 2.3000e+02 6.3200e+02 1.3600e+02]\n",
            " [0.0000e+00 0.0000e+00 0.0000e+00 ... 4.2400e+02 7.0000e+00 8.4100e+02]\n",
            " ...\n",
            " [0.0000e+00 0.0000e+00 0.0000e+00 ... 3.8682e+04 3.8683e+04 4.3190e+03]\n",
            " [0.0000e+00 0.0000e+00 0.0000e+00 ... 3.8687e+04 3.8688e+04 4.6840e+03]\n",
            " [0.0000e+00 0.0000e+00 0.0000e+00 ... 3.0100e+02 3.8689e+04 1.1218e+04]]\n"
          ]
        }
      ],
      "source": [
        "print(padded_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wphSl8QlLswz",
        "outputId": "ff9c544d-a1d0-417e-f315-6d0af8089daa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 283597 word vectors.\n"
          ]
        }
      ],
      "source": [
        "embeddings_index = dict()\n",
        "f = open('glove.6B.100d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.array(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMhMV3mdLvbW",
        "outputId": "cfbef9d8-ba35-466c-f443-f505f3fdbfb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104470\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "for word,i in tokenizer.word_index.items():\n",
        "    cur = cur+1\n",
        "print(cur)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uEX75cRBMuqm"
      },
      "outputs": [],
      "source": [
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJgKy37yMwsq",
        "outputId": "2bc2164c-8f96-4853-df8d-ebf511ed95b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 120, 100)          3869000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                42240     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 64)               256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 325       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,911,827\n",
            "Trainable params: 42,699\n",
            "Non-trainable params: 3,869,128\n",
            "_________________________________________________________________\n",
            "None\n",
            "(6500,) (62351,) (62351, 120) (6500, 120)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False),\n",
        "    tf.keras.layers.LSTM(64,activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(5, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(loss = 'binary_crossentropy', optimizer=opt,metrics = ['accuracy'])\n",
        "print(model.summary())\n",
        "print(y_dev_tf.shape,y_train_tf.shape,padded_tf.shape,testing_padded_tf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhlHalrzMzPm",
        "outputId": "458da5df-e298-44ff-9c00-1fa15dec9225"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6500, 120) (6500,) (62351, 120) (62351,)\n"
          ]
        }
      ],
      "source": [
        "print(testing_padded_tf.shape,y_dev_tf.shape,padded_tf.shape,y_train_tf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuOdPMjkM443",
        "outputId": "d334806c-1313-44ac-8942-0db6b9a61167"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1949/1949 [==============================] - 369s 187ms/step - loss: 0.6890 - accuracy: 0.6038 - val_loss: 0.6360 - val_accuracy: 0.6248\n",
            "Epoch 2/5\n",
            "1949/1949 [==============================] - 363s 186ms/step - loss: 0.6391 - accuracy: 0.6232 - val_loss: 0.6238 - val_accuracy: 0.6357\n",
            "Epoch 3/5\n",
            "1949/1949 [==============================] - 365s 187ms/step - loss: 0.6310 - accuracy: 0.6279 - val_loss: 0.6207 - val_accuracy: 0.6435\n",
            "Epoch 4/5\n",
            "1949/1949 [==============================] - 360s 184ms/step - loss: 0.6267 - accuracy: 0.6348 - val_loss: 0.6252 - val_accuracy: 0.6588\n",
            "Epoch 5/5\n",
            "1949/1949 [==============================] - 362s 186ms/step - loss: 0.6222 - accuracy: 0.6409 - val_loss: 0.6162 - val_accuracy: 0.6540\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1615344290>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "num_epochs = 5\n",
        "model.fit(padded_tf, y_train_tf, epochs=num_epochs, validation_data=(testing_padded_tf, y_dev_tf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DWzkLaYsM8zC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4449c04b-bbda-4b85-bd91-93822d689b40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: This is a wrong sentence.\n",
            "Grammatically \u001b[1m CORRECT \u001b[0m with probability:  [[0.6559517]]\n",
            "[[0.6559517]]\n",
            "['This is a wrong sentence.']\n"
          ]
        }
      ],
      "source": [
        "custom = input(\"Sentence: \")\n",
        "custom_test_1 = np.array([custom])\n",
        "custom_1 = tokenizer.texts_to_sequences(custom_test_1)\n",
        "flag = 0\n",
        "for q in custom_1[0]:\n",
        "    if q!=1: \n",
        "        flag = 1\n",
        "        break\n",
        "if flag == 0: \n",
        "    print(\"All words out of vocabulary!\")\n",
        "custom_2 = pad_sequences(custom_1,maxlen=max_length)\n",
        "custom_np = np.array(custom_2,np.float32)\n",
        "custom_tf = tf.convert_to_tensor(custom_np,np.float32)\n",
        "prob = model.predict(custom_tf)\n",
        "if prob<0.65:\n",
        "    print(\"Grammatically \\033[1m INCORRECT \\033[0m with probability: \",1-prob)\n",
        "else:\n",
        "    print(\"Grammatically \\033[1m CORRECT \\033[0m with probability: \",prob)\n",
        "print(prob)\n",
        "print(custom_test_1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "code.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}